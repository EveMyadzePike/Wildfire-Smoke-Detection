{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wildfires_Detectron2_Dataset_Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1DOEtd0pNVq_xZCP5Ya7D7UDjONgyWG-l",
      "authorship_tag": "ABX9TyOoQ8GyY/cDWrBVAfa0CErc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasonManesis/Wildfire-Smoke-Detection/blob/main/Scripts/Wildfires_Detectron2_Dataset_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I_VstUvnKGU"
      },
      "source": [
        "# Import some common libraries.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import yaml \n",
        "import os, json, cv2, random, matplotlib\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager\n",
        "import datetime\n",
        "import pytz\n",
        "from termcolor import colored"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbikwxVNnM1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c28ca030-952c-44c6-bc7b-d6b1b02c5f67"
      },
      "source": [
        "# Mount google drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RStoN-rTJa4W"
      },
      "source": [
        "# Dataset Preprocessing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm6nA47eJ9Za"
      },
      "source": [
        "```\n",
        "The folder structure of the original dataset looks like this:\n",
        "\n",
        "<dataset_dir>/\n",
        "    test/\n",
        "        <filename0>.jpg\n",
        "        <filename1>.jpg\n",
        "        ...\n",
        "        _annotations.coco.json\n",
        "    train/\n",
        "        <filename0>.jpg\n",
        "        <filename1>.jpg\n",
        "        ...\n",
        "        _annotations.coco.json\n",
        "    valid/\n",
        "        <filename0>.jpg\n",
        "        <filename1>.jpg\n",
        "        ...\n",
        "        _annotations.coco.json\n",
        "```\n",
        "```\n",
        "The folder structure of a COCO dataset looks like this:\n",
        "\n",
        "<dataset_dir>/\n",
        "    data/\n",
        "        <filename0>.<ext>\n",
        "        <filename1>.<ext>\n",
        "        ...\n",
        "    labels.json -->\n",
        "```\n",
        "```\n",
        "So we want to change the folder structure to:\n",
        "\n",
        "<dataset_dir>/\n",
        "    test/\n",
        "        data/\n",
        "            <filename0>.jpg\n",
        "            <filename1>.jpg\n",
        "            ...\n",
        "        labels.json\n",
        "    train/\n",
        "        data/\n",
        "            <filename0>.jpg\n",
        "            <filename1>.jpg\n",
        "            ...\n",
        "        labels.json\n",
        "    valid/\n",
        "        data/\n",
        "            <filename0>.jpg\n",
        "            <filename1>.jpg\n",
        "            ...\n",
        "        labels.json\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75g5r7tNg2eJ"
      },
      "source": [
        "## Fix class id key in the original .json file and change the file structure of the dataset so it corresponds to the COCO dataset folder structure. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hpQdzeSWdGe"
      },
      "source": [
        "def json_properties(json_name, annotations_directory):\n",
        "\n",
        "    \"\"\"Opens a .json file from a given directory and prints its properties.\n",
        "\n",
        "    Args:\n",
        "        json_name (str): Name of the .json file for reading.\n",
        "        annotations_directory (str): Path to the .json file.\n",
        "\n",
        "    \"\"\"\n",
        "    #Extract a list with all subfile names in the specific directory.\n",
        "    _, _, SubFiles = next(os.walk(annotations_directory)) \n",
        "\n",
        "    if json_name in SubFiles:\n",
        "        json2open = annotations_directory + '/' + json_name\n",
        "\n",
        "        #Load .json data file\n",
        "        dataset=None\n",
        "\n",
        "        try:\n",
        "            f = open(json2open)\n",
        "            dataset = json.load(f)\n",
        "            f.close()\n",
        "        \n",
        "            #Print dataset properties.\n",
        "            if isinstance(dataset,dict):\n",
        "                for i,key in enumerate(dataset.keys()): \n",
        "                    data_structure = type(dataset[key])\n",
        "                    length = len(dataset[key])\n",
        "                    print(i+1,\"|\",key,(15-len(key))*\" \",\"|\",data_structure,\n",
        "                          \"|\",length,\"element/s\")\n",
        "\n",
        "        except:\n",
        "            print(\"Error with data loading\")\n",
        "\n",
        "    else:\n",
        "        print(\"The requested .json file doesn't included in the given directory!\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXeCczDdINpk"
      },
      "source": [
        "def print_json(ttv,json_name,annotations_directory):\n",
        "\n",
        "    \"\"\"Auxillary function that works together with json_properties() for formatting the \n",
        "        printing output of the given .json file properties.\n",
        "\n",
        "    Args:\n",
        "        ttv (str): Takes one of the values \"training\", \"testing\" or \"validation\".\n",
        "        json_name (str): Name of the .json file for reading.\n",
        "        annotations_directory (str): Path to the .json file.\n",
        "\n",
        "    \"\"\"\n",
        "    print(\"Properties of .json file with annotations for \" + ttv + \":\")\n",
        "    print('--'*27)\n",
        "    json_properties(json_name,annotations_directory)\n",
        "    print('--'*27+'\\n'*2)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCKrATCUIvff",
        "outputId": "644f3b6f-1157-4e9f-dbba-2a3028a6703e"
      },
      "source": [
        "#Print the properties of the .json files:\n",
        "print_json('training','_annotations.coco.json',\"/content/drive/MyDrive/Datasets/Wildfires_2/train\")\n",
        "print_json('testing','_annotations.coco.json',\"/content/drive/MyDrive/Datasets/Wildfires_2/test\")\n",
        "print_json('validation','_annotations.coco.json',\"/content/drive/MyDrive/Datasets/Wildfires_2/valid\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Properties of .json file with annotations for training:\n",
            "------------------------------------------------------\n",
            "1 | info             | <class 'dict'> | 6 element/s\n",
            "2 | licenses         | <class 'list'> | 1 element/s\n",
            "3 | categories       | <class 'list'> | 2 element/s\n",
            "4 | images           | <class 'list'> | 516 element/s\n",
            "5 | annotations      | <class 'list'> | 516 element/s\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "Properties of .json file with annotations for testing:\n",
            "------------------------------------------------------\n",
            "1 | info             | <class 'dict'> | 6 element/s\n",
            "2 | licenses         | <class 'list'> | 1 element/s\n",
            "3 | categories       | <class 'list'> | 2 element/s\n",
            "4 | images           | <class 'list'> | 74 element/s\n",
            "5 | annotations      | <class 'list'> | 74 element/s\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "Properties of .json file with annotations for validation:\n",
            "------------------------------------------------------\n",
            "1 | info             | <class 'dict'> | 6 element/s\n",
            "2 | licenses         | <class 'list'> | 1 element/s\n",
            "3 | categories       | <class 'list'> | 2 element/s\n",
            "4 | images           | <class 'list'> | 147 element/s\n",
            "5 | annotations      | <class 'list'> | 147 element/s\n",
            "------------------------------------------------------\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Pbw3qf7QyaP",
        "outputId": "e9e3672b-f906-45b5-b30d-7a7bfb1399cb"
      },
      "source": [
        "#Inspection of the categories key in the original annotation file.\n",
        "f = open('/content/drive/MyDrive/Datasets/Wildfires_2/train/_annotations.coco.json')\n",
        "dataset = json.load(f)\n",
        "f.close()\n",
        "dataset['categories']"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 0, 'name': 'Smoke', 'supercategory': 'none'},\n",
              " {'id': 1, 'name': 'smoke', 'supercategory': 'Smoke'}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgpD5-Q-RUmx"
      },
      "source": [
        "We can see that the key 'categories' of the dataset contains two sub-dictionaries, every one of them has three keys: 'id', 'name' and 'supercategory'. The mistake in the specific annotations is that the 'name' key has the value of the positive class in this two dictionaries. That confuses the detectron2's dataset loading fuctions so it must be fixed. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON4wPYjOwpFe"
      },
      "source": [
        "def fix_jsons_keys(dataset_dir):\n",
        "\n",
        "    \"\"\"Opens the original annotation file (.json) from a given directory,\n",
        "    deletes the first sub-dictionary from  'categories' key and saves the new .json file (\"labels.json\").\n",
        "\n",
        "    Args:\n",
        "        dataset_dir (str): Path to the .json file.\n",
        "\n",
        "    \"\"\"\n",
        "    _, SubFolders, _ = next(os.walk(dataset_dir))\n",
        "\n",
        "    for folder_name in SubFolders:\n",
        "        json_2_open = dataset_dir + \"/\" + folder_name + \"/\" + \"_annotations.coco.json\"\n",
        "\n",
        "        #Open .json\n",
        "        f = open(json_2_open)\n",
        "        dataset = json.load(f)\n",
        "        f.close()\n",
        "        \n",
        "        #Delete unwanted keys.\n",
        "        if 'categories' in dataset: \n",
        "            del dataset['categories'][0]\n",
        "\n",
        "        #Save the new corrected .json.\n",
        "        jsonString = json.dumps(dataset)\n",
        "        jsonFile = open(dataset_dir + \"/\" + folder_name + \"/\" + \"labels.json\", \"w\")\n",
        "        jsonFile.write(jsonString)\n",
        "        jsonFile.close()\n",
        "\n",
        "    print(colored('Keys in .json files are now corrected !', 'green', attrs=['bold']))     "
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq8u_7Ao0VLk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea492bc3-c0ce-4a9c-ad0c-34ea8024b270"
      },
      "source": [
        "dataset_dir = \"/content/drive/MyDrive/Datasets/Wildfires_2\"\n",
        "fix_jsons_keys(dataset_dir)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[32mKeys in .json files are now corrected !\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeIXrOXczmHh",
        "outputId": "20230ce8-6665-497a-f867-640a825ee598"
      },
      "source": [
        "#Print the properties of the .json files:\n",
        "print_json('training','labels.json',\"/content/drive/MyDrive/Datasets/Wildfires_2/train\")\n",
        "print_json('testing','labels.json',\"/content/drive/MyDrive/Datasets/Wildfires_2/test\")\n",
        "print_json('validation','labels.json',\"/content/drive/MyDrive/Datasets/Wildfires_2/valid\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Properties of .json file with annotations for training:\n",
            "------------------------------------------------------\n",
            "1 | info             | <class 'dict'> | 6 element/s\n",
            "2 | licenses         | <class 'list'> | 1 element/s\n",
            "3 | categories       | <class 'list'> | 1 element/s\n",
            "4 | images           | <class 'list'> | 516 element/s\n",
            "5 | annotations      | <class 'list'> | 516 element/s\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "Properties of .json file with annotations for testing:\n",
            "------------------------------------------------------\n",
            "1 | info             | <class 'dict'> | 6 element/s\n",
            "2 | licenses         | <class 'list'> | 1 element/s\n",
            "3 | categories       | <class 'list'> | 1 element/s\n",
            "4 | images           | <class 'list'> | 74 element/s\n",
            "5 | annotations      | <class 'list'> | 74 element/s\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "Properties of .json file with annotations for validation:\n",
            "------------------------------------------------------\n",
            "1 | info             | <class 'dict'> | 6 element/s\n",
            "2 | licenses         | <class 'list'> | 1 element/s\n",
            "3 | categories       | <class 'list'> | 1 element/s\n",
            "4 | images           | <class 'list'> | 147 element/s\n",
            "5 | annotations      | <class 'list'> | 147 element/s\n",
            "------------------------------------------------------\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpdS8S4Lb3FP",
        "outputId": "020c3721-3900-4f53-e8b9-1f96d43d7931"
      },
      "source": [
        "#Inspection of the categories key in the new annotation file.\n",
        "f = open('/content/drive/MyDrive/Datasets/Wildfires_2/train/labels.json')\n",
        "dataset = json.load(f)\n",
        "f.close()\n",
        "dataset['categories']"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 1, 'name': 'smoke', 'supercategory': 'Smoke'}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGmJa7wfW71D"
      },
      "source": [
        "**OK!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I78Hf8TyXJdf"
      },
      "source": [
        "## Move image and annotation data to new folders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58KsLal2YaiO"
      },
      "source": [
        "dataset_dir = '/content/drive/MyDrive/Datasets/Wildfires_2'\n",
        "fix_jsons_keys(dataset_dir)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hVFIk50XVL0"
      },
      "source": [
        "def copy_image_data(dataset_dir):\n",
        "\n",
        "    \"\"\"Copies all image files from all three directories (train,test,valid) \n",
        "    to three new ones with different folder structure:\n",
        "    .../train -> .../train/data\n",
        "\n",
        "    Args:\n",
        "        dataset_dir (str): Path to the .json file.\n",
        "\n",
        "    \"\"\"\n",
        "    _, SubFolders, _ = next(os.walk(dataset_dir))\n",
        "\n",
        "    for subfoldername in SubFolders:\n",
        "        #the dot at the end of the string is used because we want to copy only \n",
        "        # the files of the folder and not the folder itself.\n",
        "        old_dir = dataset_dir + '/' + subfoldername + '/' + '.' \n",
        "        old_dir_color = colored(old_dir[:-1],'blue', attrs=['bold'])\n",
        "        new_dir =  dataset_dir +'_COCO'+ '/' + subfoldername + '/data/'  \n",
        "        new_dir_color = colored(new_dir,'green', attrs=['bold'])\n",
        "        os.makedirs(new_dir, exist_ok=True) #create the new directory.\n",
        "        !cp -r $old_dir $new_dir #copy all the images from old to new directory.\n",
        "        print(f'{subfoldername.capitalize()} images successfully copied from {old_dir_color} to {new_dir_color}')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHENuJmYOZKN",
        "outputId": "72bd82f4-b38d-4660-a36e-095f9f687971"
      },
      "source": [
        "copy_image_data(dataset_dir)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test images successfully copied from \u001b[1m\u001b[34m/content/drive/MyDrive/Datasets/Wildfires_2/test/\u001b[0m to \u001b[1m\u001b[32m/content/drive/MyDrive/Datasets/Wildfires_2_COCO/test/data/\u001b[0m\n",
            "Train images successfully copied from \u001b[1m\u001b[34m/content/drive/MyDrive/Datasets/Wildfires_2/train/\u001b[0m to \u001b[1m\u001b[32m/content/drive/MyDrive/Datasets/Wildfires_2_COCO/train/data/\u001b[0m\n",
            "Valid images successfully copied from \u001b[1m\u001b[34m/content/drive/MyDrive/Datasets/Wildfires_2/valid/\u001b[0m to \u001b[1m\u001b[32m/content/drive/MyDrive/Datasets/Wildfires_2_COCO/valid/data/\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUgaepEvdmDs"
      },
      "source": [
        "def copy_annotation_data(dataset_dir):\n",
        "\n",
        "    \"\"\"Copies the corrected annotation file in the new directories of the \n",
        "    dataset and deletes all the remaining annotation files.\n",
        "\n",
        "    Args:\n",
        "        dataset_dir (str): Path to the .json file.\n",
        "\n",
        "    \"\"\"\n",
        "    _, SubFolders, _ = next(os.walk(dataset_dir))\n",
        "\n",
        "    for subfoldername in SubFolders:\n",
        "        \n",
        "        #Copy corrected annotation file to the new directory.\n",
        "        source = dataset_dir + '/' + subfoldername + '/' + 'labels.json' \n",
        "        destination =  (dataset_dir +'_COCO'+ '/' + subfoldername + '/'\n",
        "            + 'labels.json')  \n",
        "        source_color = colored(source,'blue', attrs=['bold'])\n",
        "        destination_color = colored(destination,'green', attrs=['bold'])\n",
        "        !cp  $source $destination\n",
        "\n",
        "        #Delete the previous annotation files.\n",
        "        file_4_del_path_1 = (dataset_dir +'_COCO'+ '/' + subfoldername + '/data/' \n",
        "            + '_annotations.coco.json')  \n",
        "        file_4_del_path_1_c = colored(file_4_del_path_1,'red', attrs=['bold'])\n",
        "        file_4_del_path_2 = (dataset_dir +'_COCO'+ '/' + subfoldername + '/data/' \n",
        "            + 'labels.json') \n",
        "        file_4_del_path_2_c = colored(file_4_del_path_2,'red', attrs=['bold'])\n",
        "\n",
        "        !rm $file_4_del_path_1\n",
        "        !rm $file_4_del_path_2\n",
        "\n",
        "        print(f'The file: \"labels.json\" successfully copied from {source_color} to {destination_color}')\n",
        "        print(f'The file: \"_annotations.coco.json\" successfully deleted from {file_4_del_path_1_c}')\n",
        "        print(f'The file: \"labels.json\" successfully deleted from {file_4_del_path_2_c}\\n')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBvWSat3gD_Q",
        "outputId": "acd58a3b-5f7a-42fd-bb4b-55df58cdf2d7"
      },
      "source": [
        " copy_annotation_data(dataset_dir)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The file: \"labels.json\" successfully copied from \u001b[1m\u001b[34m/content/drive/MyDrive/Datasets/Wildfires_2/test/labels.json\u001b[0m to \u001b[1m\u001b[32m/content/drive/MyDrive/Datasets/Wildfires_2_COCO/test/labels.json\u001b[0m\n",
            "The file: \"_annotations.coco.json\" successfully deleted from \u001b[1m\u001b[31m/content/drive/MyDrive/Datasets/Wildfires_2_COCO/test/data/_annotations.coco.json\u001b[0m\n",
            "The file: \"labels.json\" successfully deleted from \u001b[1m\u001b[31m/content/drive/MyDrive/Datasets/Wildfires_2_COCO/test/data/labels.json\u001b[0m\n",
            "\n",
            "The file: \"labels.json\" successfully copied from \u001b[1m\u001b[34m/content/drive/MyDrive/Datasets/Wildfires_2/train/labels.json\u001b[0m to \u001b[1m\u001b[32m/content/drive/MyDrive/Datasets/Wildfires_2_COCO/train/labels.json\u001b[0m\n",
            "The file: \"_annotations.coco.json\" successfully deleted from \u001b[1m\u001b[31m/content/drive/MyDrive/Datasets/Wildfires_2_COCO/train/data/_annotations.coco.json\u001b[0m\n",
            "The file: \"labels.json\" successfully deleted from \u001b[1m\u001b[31m/content/drive/MyDrive/Datasets/Wildfires_2_COCO/train/data/labels.json\u001b[0m\n",
            "\n",
            "The file: \"labels.json\" successfully copied from \u001b[1m\u001b[34m/content/drive/MyDrive/Datasets/Wildfires_2/valid/labels.json\u001b[0m to \u001b[1m\u001b[32m/content/drive/MyDrive/Datasets/Wildfires_2_COCO/valid/labels.json\u001b[0m\n",
            "The file: \"_annotations.coco.json\" successfully deleted from \u001b[1m\u001b[31m/content/drive/MyDrive/Datasets/Wildfires_2_COCO/valid/data/_annotations.coco.json\u001b[0m\n",
            "The file: \"labels.json\" successfully deleted from \u001b[1m\u001b[31m/content/drive/MyDrive/Datasets/Wildfires_2_COCO/valid/data/labels.json\u001b[0m\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THAGTMrb8zvb"
      },
      "source": [
        "## Fix image paths in .json files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vIXsWgY8751"
      },
      "source": [
        "def change_image_path(dataset_dir):\n",
        "    \n",
        "    \"\"\"Opens a .json file from a given directory and changes the image paths.\n",
        "\n",
        "    Args:\n",
        "        dataset_dir (str): Path to the .json file.\n",
        "\n",
        "    \"\"\"\n",
        "    _, SubFolders, _ = next(os.walk(dataset_dir))\n",
        "\n",
        "    for folder_name in SubFolders:\n",
        "        images_path = dataset_dir + \"/\" + folder_name + \"/\" + \"data\"\n",
        "        _, _, image_names = next(os.walk(images_path))\n",
        "        \n",
        "        #Open .json\n",
        "        json_2_open = dataset_dir + \"/\" + folder_name + \"/\" + \"labels.json\"\n",
        "        f = open(json_2_open)\n",
        "        dataset = json.load(f)\n",
        "        f.close()\n",
        "\n",
        "        for i, image_name in enumerate(image_names):\n",
        "            # new_name = images_path + \"/\" + folder_name + \"_\" + str(i) + '.jpg'\n",
        "            # os.rename(images_path + \"/\" + image_name, new_name)\n",
        "            image_path = dataset['images'][i]['file_name']\n",
        "            filename = image_path.split(sep='/')[-1]\n",
        "            dataset['images'][i]['file_name'] = dataset_dir + \"/\" + folder_name + \"/\" + \"data\" + \"/\" + filename\n",
        "\n",
        "        #Rewrite a new corrected .json to the old one.\n",
        "        jsonString = json.dumps(dataset)\n",
        "        jsonFile = open(dataset_dir + \"/\" + folder_name + \"/\" + \"labels.json\", \"w\")\n",
        "        jsonFile.write(jsonString)\n",
        "        jsonFile.close()  \n",
        "\n",
        "    print(colored('Image paths in .json files changed successfully!', 'green', attrs=['bold']))    "
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtwJ7Pv__Fdh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7337270d-20ce-4f44-f165-95c49a16c1a6"
      },
      "source": [
        "dataset_dir = '/content/drive/MyDrive/Datasets/Wildfires_2_COCO'\n",
        "change_image_path(dataset_dir)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[32mImage paths in .json files changed successfully!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}