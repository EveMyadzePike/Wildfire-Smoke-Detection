{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wildfires_Detectron2_Model_Configuration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMR6wAQkX1+kPJmD6KwYrR6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasonManesis/Wildfire-Smoke-Detection/blob/main/Scripts/Wildfires_Detectron2_Model_Configuration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kFCfwhYw0TY"
      },
      "source": [
        "# Import some common libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import yaml \n",
        "import os, json, cv2, random, matplotlib\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager\n",
        "import datetime\n",
        "import pytz"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNTq4C6tw4oz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9584e588-8b42-4824-d388-7533ff2d584a"
      },
      "source": [
        "#Mount google drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU3YhYaEs4UA"
      },
      "source": [
        "#Install detectron2.\n",
        "\n",
        "!pip install pyyaml==5.1\n",
        "\n",
        "# !pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# Install detectron2 that matches the above pytorch version, see https://detectron2.readthedocs.io/tutorials/install.html for instructions.\n",
        "\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.9/index.html\n",
        "\n",
        "# After installation, you need to \"restart runtime\" in Colab. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSMvs4Zt0583"
      },
      "source": [
        "# Model Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkI4DJHa_9AD"
      },
      "source": [
        "def datetime_stamp(time_zone = 'Europe/Athens'):  \n",
        "  \n",
        "  \"\"\"Saves the given configuration in the output and session's directories.\n",
        "\n",
        "  Args:\n",
        "      time_zone (str): Name of the timezone in which we want the produced date-time stamp.\n",
        "\n",
        "  Returns: \n",
        "      current_date_and_time (str): The current date and time in dd_mm_yyyy__hh_mm format, based on the given timezone.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  timezone = pytz.timezone(time_zone)\n",
        "  current_date_and_time = datetime.datetime.now(tz=timezone).strftime(\"%d_%m_%Y__%H_%M\")\n",
        "\n",
        "  return current_date_and_time"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "byOqDZ2tnBP_",
        "outputId": "714f4f84-cfba-45e7-8c53-b717e5ad097d"
      },
      "source": [
        "datetime_stamp()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'24_08_2021__14_43'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TutepRQ7sewq"
      },
      "source": [
        "import detectron2\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.config.config import CfgNode as CN"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjbPfxgJ4mUK"
      },
      "source": [
        "cfg = get_cfg()\n",
        "#cfg.merge_from_file('/content/drive/MyDrive/configuration.yaml') #If we want to change an already created configuration file.\n",
        "train_dir = '/content/drive/MyDrive/Datasets/Wildfires_2_COCO/train' \n",
        "test_dir = '/content/drive/MyDrive/Datasets/Wildfires_2_COCO/test' "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIgkLEHu3ZoI"
      },
      "source": [
        "def INPUT_config(cfg, train_dir=train_dir, test_dir=test_dir, data_augmentation=True):\n",
        "\n",
        "  \"\"\"Parametrizes the configuration of the model input.\n",
        "\n",
        "  Args:\n",
        "      cfg (detectron2.config.config.CfgNode): Configuration node for parameterization.\n",
        "      train_dir (str): Path of training images directory.\n",
        "      test_dir (str): Path of training images directory.\n",
        "      data_augmentation (bool): Whether to use or not data augmentation during training.\n",
        "\n",
        "  Returns: \n",
        "       _C (detectron2.config.config.CfgNode): Parameterized configuration node of the input.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  _C = cfg\n",
        "  _C.INPUT = CN()\n",
        "  \n",
        "  for dir in (train_dir,test_dir):\n",
        "\n",
        "    #Open .json\n",
        "    json_2_open = dir + '/' + 'labels.json'\n",
        "    f = open(json_2_open)\n",
        "    dataset = json.load(f)\n",
        "    f.close()\n",
        "\n",
        "    images_df = pd.DataFrame(dataset['images'])\n",
        "    min_height = images_df['height'].min()\n",
        "    max_height = images_df['height'].max()\n",
        "    min_width = images_df['width'].min()\n",
        "    max_width = images_df['width'].max()\n",
        "    \n",
        "    if dir==train_dir:\n",
        "      _C.INPUT.MIN_SIZE_TRAIN = [min(min_height,min_width),] # Size of the smallest side of the image during training.\n",
        "      _C.INPUT.MAX_SIZE_TRAIN = max(max_height,max_width) # Maximum size of the side of the image during training.\n",
        "    else:\n",
        "      _C.INPUT.MIN_SIZE_TEST = min(min_height,min_width) # Size of the smallest side of the image during testing. Set to zero to disable resize in testing.\n",
        "      _C.INPUT.MAX_SIZE_TEST = max(max_height,max_width) # Maximum size of the side of the image during testing.\n",
        "    \n",
        "    if data_augmentation == True:\n",
        "      \n",
        "      _C.INPUT.RANDOM_FLIP = \"horizontal\" # Mode for flipping images used in data augmentation during training, choose one of [\"horizontal, \"vertical\", \"none\"].\n",
        "      _C.INPUT.CROP = CN({\"ENABLED\": True}) # `True` if cropping is used for data augmentation during training.\n",
        "      _C.INPUT.CROP.TYPE = \"relative_range\" # Cropping type. See documentation of `detectron2.data.transforms.RandomCrop` for explanation.\n",
        "      _C.INPUT.CROP.SIZE = [0.9, 0.9] # Size of crop in range (0, 1] if CROP.TYPE is \"relative\" or \"relative_range\" and in number of pixels if CROP.TYPE is \"absolute\".\n",
        "\n",
        "  return _C"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J54HXpEQOMH9"
      },
      "source": [
        "def BB_FPN_PG_configs(cfg):\n",
        "\n",
        "  \"\"\"Parametrizes the configuration of the Backbone, FPN and Proposal generator modules.\n",
        "\n",
        "  Args:\n",
        "      cfg (detectron2.config.config.CfgNode): Configuration node for parameterization.\n",
        "\n",
        "  Returns: \n",
        "       _C (detectron2.config.config.CfgNode): Parameterized configuration node of the of the Backbone, FPN and Proposal generator modules.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  _C = cfg  \n",
        "\n",
        "  # ---------------------------------------------------------------------------- #\n",
        "  # Backbone options\n",
        "  # ---------------------------------------------------------------------------- #\n",
        "  _C.MODEL.BACKBONE = CN()\n",
        "\n",
        "  _C.MODEL.BACKBONE.NAME = \"build_resnet_backbone\"\n",
        "  # Freeze the first several stages so they are not trained.\n",
        "  # There are 5 stages in ResNet. The first is a convolution, and the following\n",
        "  # stages are each group of residual blocks.\n",
        "  _C.MODEL.BACKBONE.FREEZE_AT = 2\n",
        "\n",
        "\n",
        "  # ---------------------------------------------------------------------------- #\n",
        "  # FPN options\n",
        "  # ---------------------------------------------------------------------------- #\n",
        "  _C.MODEL.FPN = CN()\n",
        "  # Names of the input feature maps to be used by FPN\n",
        "  # They must have contiguous power of 2 strides\n",
        "  # e.g., [\"res2\", \"res3\", \"res4\", \"res5\"]\n",
        "  _C.MODEL.FPN.IN_FEATURES = []\n",
        "  _C.MODEL.FPN.OUT_CHANNELS = 256\n",
        "\n",
        "  # Options: \"\" (no norm), \"GN\"\n",
        "  _C.MODEL.FPN.NORM = \"\"\n",
        "\n",
        "  # Types for fusing the FPN top-down and lateral features. Can be either \"sum\" or \"avg\"\n",
        "  _C.MODEL.FPN.FUSE_TYPE = \"sum\"\n",
        "\n",
        "\n",
        "  # ---------------------------------------------------------------------------- #\n",
        "  # Proposal generator options\n",
        "  # ---------------------------------------------------------------------------- #\n",
        "  _C.MODEL.PROPOSAL_GENERATOR = CN()\n",
        "  # Current proposal generators include \"RPN\", \"RRPN\" and \"PrecomputedProposals\"\n",
        "  _C.MODEL.PROPOSAL_GENERATOR.NAME = \"RPN\"\n",
        "  # Proposal height and width both need to be greater than MIN_SIZE\n",
        "  # (a the scale used during training or inference)\n",
        "  _C.MODEL.PROPOSAL_GENERATOR.MIN_SIZE = 0\n",
        "\n",
        "  return _C"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XTHQxgqQlAd"
      },
      "source": [
        "def Anchor_Generator_config(cfg):\n",
        "\n",
        "  \"\"\"Parametrizes the configuration of the anchor generator module.\n",
        "\n",
        "  Args:\n",
        "      cfg (detectron2.config.config.CfgNode): Configuration node for parameterization.\n",
        "\n",
        "  Returns: \n",
        "       _C (detectron2.config.config.CfgNode): Parameterized configuration node of the of the anchor generator module.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  _C = cfg\n",
        "  _C.MODEL.ANCHOR_GENERATOR = CN()\n",
        "  \n",
        "  # The generator can be any name in the ANCHOR_GENERATOR registry\n",
        "  _C.MODEL.ANCHOR_GENERATOR.NAME = \"DefaultAnchorGenerator\"\n",
        "  # Anchor sizes (i.e. sqrt of area) in absolute pixels w.r.t. the network input.\n",
        "  # Format: list[list[float]]. SIZES[i] specifies the list of sizes to use for\n",
        "  # IN_FEATURES[i]; len(SIZES) must be equal to len(IN_FEATURES) or 1.\n",
        "  # When len(SIZES) == 1, SIZES[0] is used for all IN_FEATURES.\n",
        "  _C.MODEL.ANCHOR_GENERATOR.SIZES = [[8, 16, 32, 48, 64, 96, 128, 196, 256, 320, 384, 512]]\n",
        "  # Anchor aspect ratios. For each area given in `SIZES`, anchors with different aspect\n",
        "  # ratios are generated by an anchor generator.\n",
        "  # Format: list[list[float]]. ASPECT_RATIOS[i] specifies the list of aspect ratios (H/W)\n",
        "  # to use for IN_FEATURES[i]; len(ASPECT_RATIOS) == len(IN_FEATURES) must be true,\n",
        "  # or len(ASPECT_RATIOS) == 1 is true and aspect ratio list ASPECT_RATIOS[0] is used\n",
        "  # for all IN_FEATURES.\n",
        "  _C.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.25, 0.5, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0]]\n",
        "  # Anchor angles.\n",
        "  # list[list[float]], the angle in degrees, for each input feature map.\n",
        "  # ANGLES[i] specifies the list of angles for IN_FEATURES[i].\n",
        "  _C.MODEL.ANCHOR_GENERATOR.ANGLES = [0, 90]\n",
        "  # Relative offset between the center of the first anchor and the top-left corner of the image\n",
        "  # Value has to be in [0, 1). Recommend to use 0.5, which means half stride.\n",
        "  # The value is not expected to affect model accuracy.\n",
        "  _C.MODEL.ANCHOR_GENERATOR.OFFSET = 0.5\n",
        "\n",
        "  return _C"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWJKQoMTyIXn"
      },
      "source": [
        "def RPN_config(cfg):\n",
        "\n",
        "  \"\"\"Parametrizes the configuration of the Region Proposal Network model.\n",
        "\n",
        "  Args:\n",
        "      cfg (detectron2.config.config.CfgNode): Configuration node for parameterization.\n",
        "\n",
        "  Returns: \n",
        "       _C (detectron2.config.config.CfgNode): Parameterized configuration node of the Region Proposal Network model.\n",
        "\n",
        "  \"\"\"\n",
        "  \n",
        "  _C = cfg\n",
        "  _C.MODEL.RPN = CN()\n",
        "\n",
        "  _C.MODEL.RPN.HEAD_NAME = \"StandardRPNHead\"  # used by RPN_HEAD_REGISTRY\n",
        "  _C.MODEL.RPN.IOU_THRESHOLDS = [0.4, 0.7]\n",
        "  _C.MODEL.RPN.IOU_LABELS = [0, -1, 1]\n",
        "  # Number of regions per image used to train RPN\n",
        "  _C.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
        "  # Target fraction of foreground (positive) examples per RPN minibatch\n",
        "  _C.MODEL.RPN.POSITIVE_FRACTION = 0.5\n",
        "  # Options are: \"smooth_l1\", \"giou\"\n",
        "  _C.MODEL.RPN.BBOX_REG_LOSS_TYPE = \"smooth_l1\"\n",
        "  _C.MODEL.RPN.BBOX_REG_LOSS_WEIGHT = 1.0\n",
        "  # Weights on (dx, dy, dw, dh) for normalizing RPN anchor regression targets\n",
        "  _C.MODEL.RPN.BBOX_REG_WEIGHTS = (1.0, 1.0, 1.0, 1.0)\n",
        "  # The transition point from L1 to L2 loss. Set to 0.0 to make the loss simply L1.\n",
        "  _C.MODEL.RPN.SMOOTH_L1_BETA = 0.0\n",
        "  _C.MODEL.RPN.LOSS_WEIGHT = 1.0\n",
        "  # Number of top scoring RPN proposals to keep before applying NMS\n",
        "  # When FPN is used, this is *per FPN level* (not total)\n",
        "  _C.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 12000\n",
        "  _C.MODEL.RPN.PRE_NMS_TOPK_TEST = 6000\n",
        "  # Number of top scoring RPN proposals to keep after applying NMS\n",
        "  # When FPN is used, this limit is applied per level and then again to the union\n",
        "  # of proposals from all levels\n",
        "  # NOTE: When FPN is used, the meaning of this config is different from Detectron1.\n",
        "  # It means per-batch topk in Detectron1, but per-image topk here.\n",
        "  # See the \"find_top_rpn_proposals\" function for details.\n",
        "  _C.MODEL.RPN.POST_NMS_TOPK_TRAIN = 2000\n",
        "  _C.MODEL.RPN.POST_NMS_TOPK_TEST = 1000\n",
        "  # NMS threshold used on RPN proposals\n",
        "  _C.MODEL.RPN.NMS_THRESH = 0.6\n",
        "  # Set this to -1 to use the same number of output channels as input channels.\n",
        "  _C.MODEL.RPN.CONV_DIMS = [-1]\n",
        "  \n",
        "  return _C"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk5QOrQ-xzZl"
      },
      "source": [
        "def ROI_Heads_config(cfg):\n",
        "\n",
        "  \"\"\"Parametrizes the configuration of the ROI heads.\n",
        "\n",
        "  Args:\n",
        "      cfg (detectron2.config.config.CfgNode): Configuration node for parameterization.\n",
        "\n",
        "  Returns: \n",
        "       _C (detectron2.config.config.CfgNode): Parameterized configuration node of the ROI heads.\n",
        "\n",
        "  \"\"\"\n",
        "  _C = cfg\n",
        "  _C.MODEL.ROI_HEADS = CN()\n",
        "\n",
        "  _C.MODEL.ROI_HEADS.NAME = \"Res5ROIHeads\"\n",
        "  # Number of foreground classes\n",
        "  _C.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "  # Names of the input feature maps to be used by ROI heads\n",
        "  # Currently all heads (box, mask, ...) use the same input feature map list\n",
        "  # e.g., [\"p2\", \"p3\", \"p4\", \"p5\"] is commonly used for FPN\n",
        "  _C.MODEL.ROI_HEADS.IN_FEATURES = [\"res4\"]\n",
        "  # IOU overlap ratios [IOU_THRESHOLD]\n",
        "  # Overlap threshold for an RoI to be considered background (if < IOU_THRESHOLD)\n",
        "  # Overlap threshold for an RoI to be considered foreground (if >= IOU_THRESHOLD)\n",
        "  _C.MODEL.ROI_HEADS.IOU_THRESHOLDS = [0.5]\n",
        "  _C.MODEL.ROI_HEADS.IOU_LABELS = [0, 1]\n",
        "  # RoI minibatch size *per image* (number of regions of interest [ROIs])\n",
        "  # Total number of RoIs per training minibatch =\n",
        "  #   ROI_HEADS.BATCH_SIZE_PER_IMAGE * SOLVER.IMS_PER_BATCH\n",
        "  # E.g., a common configuration is: 512 * 16 = 8192\n",
        "  _C.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
        "  # Target fraction of RoI minibatch that is labeled foreground (i.e. class > 0)\n",
        "  _C.MODEL.ROI_HEADS.POSITIVE_FRACTION = 0.25\n",
        "\n",
        "  # Only used on test mode\n",
        "\n",
        "  # Minimum score threshold (assuming scores in a [0, 1] range); a value chosen to\n",
        "  # balance obtaining high recall with not having too many low precision\n",
        "  # detections that will slow down inference post processing steps (like NMS)\n",
        "  # A default threshold of 0.0 increases AP by ~0.2-0.3 but significantly slows down\n",
        "  # inference.\n",
        "  _C.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.05\n",
        "  # Overlap threshold used for non-maximum suppression (suppress boxes with\n",
        "  # IoU >= this threshold)\n",
        "  _C.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.5\n",
        "  # If True, augment proposals with ground-truth boxes before sampling proposals to\n",
        "  # train ROI heads.\n",
        "  _C.MODEL.ROI_HEADS.PROPOSAL_APPEND_GT = True\n",
        "\n",
        "  return _C"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN1LvMbSQtj5"
      },
      "source": [
        "def Box_Head_config(cfg):\n",
        "\n",
        "  \"\"\"Parametrizes the configuration of the ROI box heads.\n",
        "\n",
        "  Args:\n",
        "      cfg (detectron2.config.config.CfgNode): Configuration node for parameterization.\n",
        "\n",
        "  Returns: \n",
        "       _C (detectron2.config.config.CfgNode): Parameterized configuration node of the ROI box heads.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  _C = cfg\n",
        "  _C.MODEL.ROI_BOX_HEAD = CN()\n",
        "\n",
        "  # C4 don't use head name option\n",
        "  # Options for non-C4 models: FastRCNNConvFCHead,\n",
        "  _C.MODEL.ROI_BOX_HEAD.NAME = \"FastRCNNConvFCHead\"\n",
        "  # Options are: \"smooth_l1\", \"giou\"\n",
        "  _C.MODEL.ROI_BOX_HEAD.BBOX_REG_LOSS_TYPE = \"smooth_l1\"\n",
        "  # The final scaling coefficient on the box regression loss, used to balance the magnitude of its\n",
        "  # gradients with other losses in the model. See also `MODEL.ROI_KEYPOINT_HEAD.LOSS_WEIGHT`.\n",
        "  _C.MODEL.ROI_BOX_HEAD.BBOX_REG_LOSS_WEIGHT = 1.0\n",
        "  # Default weights on (dx, dy, dw, dh) for normalizing bbox regression targets\n",
        "  # These are empirically chosen to approximately lead to unit variance targets\n",
        "  _C.MODEL.ROI_BOX_HEAD.BBOX_REG_WEIGHTS = (10.0, 10.0, 5.0, 5.0)\n",
        "  # The transition point from L1 to L2 loss. Set to 0.0 to make the loss simply L1.\n",
        "  _C.MODEL.ROI_BOX_HEAD.SMOOTH_L1_BETA = 0.0\n",
        "  _C.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION = 14\n",
        "  _C.MODEL.ROI_BOX_HEAD.POOLER_SAMPLING_RATIO = 0\n",
        "  # Type of pooling operation applied to the incoming feature map for each RoI\n",
        "  _C.MODEL.ROI_BOX_HEAD.POOLER_TYPE = \"ROIAlignV2\"\n",
        "\n",
        "  _C.MODEL.ROI_BOX_HEAD.NUM_FC = 0\n",
        "  # Hidden layer dimension for FC layers in the RoI box head\n",
        "  _C.MODEL.ROI_BOX_HEAD.FC_DIM = 1024\n",
        "  _C.MODEL.ROI_BOX_HEAD.NUM_CONV = 0\n",
        "  # Channel dimension for Conv layers in the RoI box head\n",
        "  _C.MODEL.ROI_BOX_HEAD.CONV_DIM = 256\n",
        "  # Normalization method for the convolution layers.\n",
        "  # Options: \"\" (no norm), \"GN\", \"SyncBN\".\n",
        "  _C.MODEL.ROI_BOX_HEAD.NORM = \"\"\n",
        "  # Whether to use class agnostic for bbox regression\n",
        "  _C.MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG = False\n",
        "  # If true, RoI heads use bounding boxes predicted by the box head rather than proposal boxes.\n",
        "  _C.MODEL.ROI_BOX_HEAD.TRAIN_ON_PRED_BOXES = False\n",
        "\n",
        "  return _C"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlV6CMcM0mhh"
      },
      "source": [
        "def ResNets_config(cfg):\n",
        "\n",
        "  \"\"\"Parametrizes the configuration of the ResNet network/s.\n",
        "\n",
        "  Args:\n",
        "      cfg (detectron2.config.config.CfgNode): Configuration node for parameterization.\n",
        "\n",
        "  Returns: \n",
        "       _C (detectron2.config.config.CfgNode): Parameterized configuration node of the ResNet network/s.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  _C = cfg \n",
        "  _C.MODEL.RESNETS = CN()\n",
        "\n",
        "  # Note that parts of a resnet may be used for both the backbone and the head\n",
        "  # These options apply to both\n",
        "\n",
        "  _C.MODEL.RESNETS.DEPTH = 50\n",
        "  _C.MODEL.RESNETS.OUT_FEATURES = [\"res4\"]  # res4 for C4 backbone, res2..5 for FPN backbone\n",
        "\n",
        "  # Number of groups to use; 1 ==> ResNet; > 1 ==> ResNeXt\n",
        "  _C.MODEL.RESNETS.NUM_GROUPS = 1\n",
        "\n",
        "  # Options: FrozenBN, GN, \"SyncBN\", \"BN\"\n",
        "  _C.MODEL.RESNETS.NORM = \"FrozenBN\"\n",
        "\n",
        "  # Baseline width of each group.\n",
        "  # Scaling this parameters will scale the width of all bottleneck layers.\n",
        "  _C.MODEL.RESNETS.WIDTH_PER_GROUP = 64\n",
        "\n",
        "  # Place the stride 2 conv on the 1x1 filter\n",
        "  # Use True only for the original MSRA ResNet; use False for C2 and Torch models\n",
        "  _C.MODEL.RESNETS.STRIDE_IN_1X1 = True\n",
        "\n",
        "  # Apply dilation in stage \"res5\"\n",
        "  _C.MODEL.RESNETS.RES5_DILATION = 1\n",
        "\n",
        "  # Output width of res2. Scaling this parameters will scale the width of all 1x1 convs in ResNet\n",
        "  # For R18 and R34, this needs to be set to 64\n",
        "  _C.MODEL.RESNETS.RES2_OUT_CHANNELS = 256\n",
        "  _C.MODEL.RESNETS.STEM_OUT_CHANNELS = 64\n",
        "\n",
        "  # Apply Deformable Convolution in stages\n",
        "  # Specify if apply deform_conv on Res2, Res3, Res4, Res5\n",
        "  _C.MODEL.RESNETS.DEFORM_ON_PER_STAGE = [False, False, False, False]\n",
        "  # Use True to use modulated deform_conv (DeformableV2, https://arxiv.org/abs/1811.11168);\n",
        "  # Use False for DeformableV1.\n",
        "  _C.MODEL.RESNETS.DEFORM_MODULATED = False\n",
        "  # Number of groups in deformable conv.\n",
        "  _C.MODEL.RESNETS.DEFORM_NUM_GROUPS = 1\n",
        "\n",
        "  return _C"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wCIeD1iMSip"
      },
      "source": [
        "#Extract config properties\n",
        "cfg = get_cfg()\n",
        "Config = INPUT_config(cfg, train_dir=train_dir, test_dir=test_dir)\n",
        "Config = BB_FPN_PG_configs(Config)\n",
        "Config = Anchor_Generator_config(Config)\n",
        "Config = RPN_config(Config)\n",
        "Config = ROI_Heads_config(Config)\n",
        "Config = Box_Head_config(Config)\n",
        "Config = ResNets_config(Config)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BRsFSDHj9Fs"
      },
      "source": [
        "def save_config(cfg,file_name):\n",
        "\n",
        "  \"\"\"Saves the given configuration in the output and session's directories.\n",
        "\n",
        "  Args:\n",
        "      cfg (detectron2.config.config.CfgNode): Model's configuration.\n",
        "      file_name (str): Name for saving .yaml file (default is 'configuration.yaml').\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  saving_path = \"/content/drive/MyDrive\" + '/' + file_name\n",
        "  \n",
        "  #Save configuration to file.\n",
        "  with open(saving_path, \"w\") as f:\n",
        "    f.write(cfg.dump())   \n",
        "  \n",
        "  #Copy output configuration in the session's directory.\n",
        "  !cp $saving_path $file_name\n",
        "  \n",
        "  #Check if the given configuration saved successfully.\n",
        "  test_cfg = get_cfg()\n",
        "  test_cfg.merge_from_file(file_name)\n",
        "  if test_cfg:\n",
        "    print(\"Model configuration saved successfully!\")\n",
        "    cfg.freeze()\n",
        "  else: print(\"Error in model configuration saving\")  "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jh23R9_oXPk"
      },
      "source": [
        "def inspect_yaml(configuration_dir):\n",
        "\n",
        "  \"\"\"Opens the input .yaml file and prints its key-value pairs.\n",
        "\n",
        "  Args:\n",
        "      configuration_dir (str): Saved configuration's directory.\n",
        "\n",
        "  \"\"\"\n",
        "  stream = open(configuration_dir, 'r')\n",
        "  dictionary = yaml.safe_load(stream)\n",
        "  for key, value in dictionary.items():\n",
        "      print('\\n')\n",
        "      print (key + \" : \" + str(value))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn9pwjHxkU_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba4b685a-0162-4a88-acfc-bd13b5379f0f"
      },
      "source": [
        "save_config(Config, file_name = 'configuration_' + datetime_stamp() + '.yaml')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model configuration saved successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCEtIiwLOnoL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c5d737c-2b25-4226-e6a2-746adaecc9aa"
      },
      "source": [
        "inspect_yaml('/content/configuration_24_08_2021__14_43.yaml')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "CUDNN_BENCHMARK : False\n",
            "\n",
            "\n",
            "DATALOADER : {'ASPECT_RATIO_GROUPING': True, 'FILTER_EMPTY_ANNOTATIONS': True, 'NUM_WORKERS': 4, 'REPEAT_THRESHOLD': 0.0, 'SAMPLER_TRAIN': 'TrainingSampler'}\n",
            "\n",
            "\n",
            "DATASETS : {'PRECOMPUTED_PROPOSAL_TOPK_TEST': 1000, 'PRECOMPUTED_PROPOSAL_TOPK_TRAIN': 2000, 'PROPOSAL_FILES_TEST': [], 'PROPOSAL_FILES_TRAIN': [], 'TEST': [], 'TRAIN': []}\n",
            "\n",
            "\n",
            "GLOBAL : {'HACK': 1.0}\n",
            "\n",
            "\n",
            "INPUT : {'CROP': {'ENABLED': True, 'SIZE': [0.9, 0.9], 'TYPE': 'relative_range'}, 'MAX_SIZE_TEST': 640, 'MAX_SIZE_TRAIN': 640, 'MIN_SIZE_TEST': 480, 'MIN_SIZE_TRAIN': [480], 'RANDOM_FLIP': 'horizontal'}\n",
            "\n",
            "\n",
            "MODEL : {'ANCHOR_GENERATOR': {'ANGLES': [0, 90], 'ASPECT_RATIOS': [[0.25, 0.5, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0]], 'NAME': 'DefaultAnchorGenerator', 'OFFSET': 0.5, 'SIZES': [[8, 16, 32, 48, 64, 96, 128, 196, 256, 320, 384, 512]]}, 'BACKBONE': {'FREEZE_AT': 2, 'NAME': 'build_resnet_backbone'}, 'DEVICE': 'cuda', 'FPN': {'FUSE_TYPE': 'sum', 'IN_FEATURES': [], 'NORM': '', 'OUT_CHANNELS': 256}, 'KEYPOINT_ON': False, 'LOAD_PROPOSALS': False, 'MASK_ON': False, 'META_ARCHITECTURE': 'GeneralizedRCNN', 'PANOPTIC_FPN': {'COMBINE': {'ENABLED': True, 'INSTANCES_CONFIDENCE_THRESH': 0.5, 'OVERLAP_THRESH': 0.5, 'STUFF_AREA_LIMIT': 4096}, 'INSTANCE_LOSS_WEIGHT': 1.0}, 'PIXEL_MEAN': [103.53, 116.28, 123.675], 'PIXEL_STD': [1.0, 1.0, 1.0], 'PROPOSAL_GENERATOR': {'MIN_SIZE': 0, 'NAME': 'RPN'}, 'RESNETS': {'DEFORM_MODULATED': False, 'DEFORM_NUM_GROUPS': 1, 'DEFORM_ON_PER_STAGE': [False, False, False, False], 'DEPTH': 50, 'NORM': 'FrozenBN', 'NUM_GROUPS': 1, 'OUT_FEATURES': ['res4'], 'RES2_OUT_CHANNELS': 256, 'RES5_DILATION': 1, 'STEM_OUT_CHANNELS': 64, 'STRIDE_IN_1X1': True, 'WIDTH_PER_GROUP': 64}, 'RETINANET': {'BBOX_REG_LOSS_TYPE': 'smooth_l1', 'BBOX_REG_WEIGHTS': [1.0, 1.0, 1.0, 1.0], 'FOCAL_LOSS_ALPHA': 0.25, 'FOCAL_LOSS_GAMMA': 2.0, 'IN_FEATURES': ['p3', 'p4', 'p5', 'p6', 'p7'], 'IOU_LABELS': [0, -1, 1], 'IOU_THRESHOLDS': [0.4, 0.5], 'NMS_THRESH_TEST': 0.5, 'NORM': '', 'NUM_CLASSES': 80, 'NUM_CONVS': 4, 'PRIOR_PROB': 0.01, 'SCORE_THRESH_TEST': 0.05, 'SMOOTH_L1_LOSS_BETA': 0.1, 'TOPK_CANDIDATES_TEST': 1000}, 'ROI_BOX_CASCADE_HEAD': {'BBOX_REG_WEIGHTS': [[10.0, 10.0, 5.0, 5.0], [20.0, 20.0, 10.0, 10.0], [30.0, 30.0, 15.0, 15.0]], 'IOUS': [0.5, 0.6, 0.7]}, 'ROI_BOX_HEAD': {'BBOX_REG_LOSS_TYPE': 'smooth_l1', 'BBOX_REG_LOSS_WEIGHT': 1.0, 'BBOX_REG_WEIGHTS': [10.0, 10.0, 5.0, 5.0], 'CLS_AGNOSTIC_BBOX_REG': False, 'CONV_DIM': 256, 'FC_DIM': 1024, 'NAME': 'FastRCNNConvFCHead', 'NORM': '', 'NUM_CONV': 0, 'NUM_FC': 0, 'POOLER_RESOLUTION': 14, 'POOLER_SAMPLING_RATIO': 0, 'POOLER_TYPE': 'ROIAlignV2', 'SMOOTH_L1_BETA': 0.0, 'TRAIN_ON_PRED_BOXES': False}, 'ROI_HEADS': {'BATCH_SIZE_PER_IMAGE': 512, 'IN_FEATURES': ['res4'], 'IOU_LABELS': [0, 1], 'IOU_THRESHOLDS': [0.5], 'NAME': 'Res5ROIHeads', 'NMS_THRESH_TEST': 0.5, 'NUM_CLASSES': 1, 'POSITIVE_FRACTION': 0.25, 'PROPOSAL_APPEND_GT': True, 'SCORE_THRESH_TEST': 0.05}, 'ROI_KEYPOINT_HEAD': {'CONV_DIMS': [512, 512, 512, 512, 512, 512, 512, 512], 'LOSS_WEIGHT': 1.0, 'MIN_KEYPOINTS_PER_IMAGE': 1, 'NAME': 'KRCNNConvDeconvUpsampleHead', 'NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS': True, 'NUM_KEYPOINTS': 17, 'POOLER_RESOLUTION': 14, 'POOLER_SAMPLING_RATIO': 0, 'POOLER_TYPE': 'ROIAlignV2'}, 'ROI_MASK_HEAD': {'CLS_AGNOSTIC_MASK': False, 'CONV_DIM': 256, 'NAME': 'MaskRCNNConvUpsampleHead', 'NORM': '', 'NUM_CONV': 0, 'POOLER_RESOLUTION': 14, 'POOLER_SAMPLING_RATIO': 0, 'POOLER_TYPE': 'ROIAlignV2'}, 'RPN': {'BATCH_SIZE_PER_IMAGE': 512, 'BBOX_REG_LOSS_TYPE': 'smooth_l1', 'BBOX_REG_LOSS_WEIGHT': 1.0, 'BBOX_REG_WEIGHTS': [1.0, 1.0, 1.0, 1.0], 'CONV_DIMS': [-1], 'HEAD_NAME': 'StandardRPNHead', 'IOU_LABELS': [0, -1, 1], 'IOU_THRESHOLDS': [0.4, 0.7], 'LOSS_WEIGHT': 1.0, 'NMS_THRESH': 0.6, 'POSITIVE_FRACTION': 0.5, 'POST_NMS_TOPK_TEST': 1000, 'POST_NMS_TOPK_TRAIN': 2000, 'PRE_NMS_TOPK_TEST': 6000, 'PRE_NMS_TOPK_TRAIN': 12000, 'SMOOTH_L1_BETA': 0.0}, 'SEM_SEG_HEAD': {'COMMON_STRIDE': 4, 'CONVS_DIM': 128, 'IGNORE_VALUE': 255, 'IN_FEATURES': ['p2', 'p3', 'p4', 'p5'], 'LOSS_WEIGHT': 1.0, 'NAME': 'SemSegFPNHead', 'NORM': 'GN', 'NUM_CLASSES': 54}, 'WEIGHTS': ''}\n",
            "\n",
            "\n",
            "OUTPUT_DIR : ./output\n",
            "\n",
            "\n",
            "SEED : -1\n",
            "\n",
            "\n",
            "SOLVER : {'AMP': {'ENABLED': False}, 'BASE_LR': 0.001, 'BIAS_LR_FACTOR': 1.0, 'CHECKPOINT_PERIOD': 5000, 'CLIP_GRADIENTS': {'CLIP_TYPE': 'value', 'CLIP_VALUE': 1.0, 'ENABLED': False, 'NORM_TYPE': 2.0}, 'GAMMA': 0.1, 'IMS_PER_BATCH': 16, 'LR_SCHEDULER_NAME': 'WarmupMultiStepLR', 'MAX_ITER': 40000, 'MOMENTUM': 0.9, 'NESTEROV': False, 'REFERENCE_WORLD_SIZE': 0, 'STEPS': [30000], 'WARMUP_FACTOR': 0.001, 'WARMUP_ITERS': 1000, 'WARMUP_METHOD': 'linear', 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0.0001, 'WEIGHT_DECAY_NORM': 0.0}\n",
            "\n",
            "\n",
            "TEST : {'AUG': {'ENABLED': False, 'FLIP': True, 'MAX_SIZE': 4000, 'MIN_SIZES': [400, 500, 600, 700, 800, 900, 1000, 1100, 1200]}, 'DETECTIONS_PER_IMAGE': 100, 'EVAL_PERIOD': 0, 'EXPECTED_RESULTS': [], 'KEYPOINT_OKS_SIGMAS': [], 'PRECISE_BN': {'ENABLED': False, 'NUM_ITER': 200}}\n",
            "\n",
            "\n",
            "VERSION : 2\n",
            "\n",
            "\n",
            "VIS_PERIOD : 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}