{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wildfires_Detectron2_Model_Configuration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1JadBkC3O9P6yaulcOaEafxnmK-6soLfv",
      "authorship_tag": "ABX9TyNoX5/54zBnZd06ItBB7x9y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasonManesis/Wildfire-Smoke-Detection/blob/main/Scripts/Wildfires_Detectron2_Model_Configuration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Nt8wdGBhE0P"
      },
      "source": [
        "!pip install --upgrade watermark blackcellmagic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU1r8Z_YhI9n"
      },
      "source": [
        "%load_ext blackcellmagic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kFCfwhYw0TY"
      },
      "source": [
        "# Import some common libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import yaml \n",
        "import os, json, cv2, random, matplotlib\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager\n",
        "import datetime\n",
        "import pytz"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNTq4C6tw4oz"
      },
      "source": [
        "#Mount google drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU3YhYaEs4UA"
      },
      "source": [
        "#Install detectron2.\n",
        "\n",
        "!pip install pyyaml==5.1\n",
        "\n",
        "# !pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# Install detectron2 that matches the above pytorch version, see https://detectron2.readthedocs.io/tutorials/install.html for instructions.\n",
        "\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.9/index.html\n",
        "\n",
        "# After installation, you need to \"restart runtime\" in Colab. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSMvs4Zt0583"
      },
      "source": [
        "# Model Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkI4DJHa_9AD"
      },
      "source": [
        "def datetime_stamp(time_zone = 'Europe/Athens'):  \n",
        "  \n",
        "    \"\"\"Saves the given configuration in the output and session's directories.\n",
        "\n",
        "    Args:\n",
        "        time_zone (str): Name of the timezone in which we want the produced \n",
        "        date-time stamp.\n",
        "\n",
        "    Returns: \n",
        "        current_date_and_time (str): The current date and time in \n",
        "        dd_mm_yyyy__hh_mm format, based on the given timezone.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    timezone = pytz.timezone(time_zone)\n",
        "    current_date_and_time = datetime.datetime.now(tz=timezone)\n",
        "    current_date_and_time = current_date_and_time.strftime(\"%d_%m_%Y__%H_%M\")\n",
        "\n",
        "    return current_date_and_time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TutepRQ7sewq"
      },
      "source": [
        "import detectron2\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.config.config import CfgNode as CN"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjbPfxgJ4mUK"
      },
      "source": [
        "cfg = get_cfg()\n",
        "# If we want to change an already created configuration file.\n",
        "#cfg.merge_from_file('/content/drive/MyDrive/configuration.yaml') \n",
        "train_dir = '/content/drive/MyDrive/Datasets/Wildfires_2_COCO/train' \n",
        "test_dir = '/content/drive/MyDrive/Datasets/Wildfires_2_COCO/test' "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIgkLEHu3ZoI"
      },
      "source": [
        "def INPUT_config(cfg, train_dir=train_dir, test_dir=test_dir, data_augmentation=True):\n",
        "\n",
        "    \"\"\"Parametrizes the configuration of the model input.\n",
        "\n",
        "    Args:\n",
        "        cfg (detectron2.config.config.CfgNode): Configuration node for \n",
        "        parameterization.\n",
        "        train_dir (str): Path of training images directory.\n",
        "        test_dir (str): Path of training images directory.\n",
        "        data_augmentation (bool): Whether to use or not data augmentation \n",
        "        during training.\n",
        "\n",
        "    Returns: \n",
        "        _C (detectron2.config.config.CfgNode): Parameterized configuration \n",
        "        node of the input.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    _C = cfg\n",
        "    _C.INPUT = CN()\n",
        "    \n",
        "    for dir in (train_dir,test_dir):\n",
        "\n",
        "        #Open .json\n",
        "        json_2_open = dir + '/' + 'labels.json'\n",
        "        f = open(json_2_open)\n",
        "        dataset = json.load(f)\n",
        "        f.close()\n",
        "\n",
        "        images_df = pd.DataFrame(dataset['images'])\n",
        "        min_height = images_df['height'].min()\n",
        "        max_height = images_df['height'].max()\n",
        "        min_width = images_df['width'].min()\n",
        "        max_width = images_df['width'].max()\n",
        "        \n",
        "        if dir==train_dir:\n",
        "            # Size of the smallest side of the image during training.(list)\n",
        "            _C.INPUT.MIN_SIZE_TRAIN = [min(min_height,min_width),] \n",
        "            # Maximum size of the side of the image during training.\n",
        "            _C.INPUT.MAX_SIZE_TRAIN = max(max_height,max_width) \n",
        "        else:\n",
        "            # Size of the smallest side of the image during testing. \n",
        "            # Set to zero to disable resize in testing.\n",
        "            _C.INPUT.MIN_SIZE_TEST = min(min_height,min_width) \n",
        "            # Maximum size of the side of the image during testing.\n",
        "            _C.INPUT.MAX_SIZE_TEST = max(max_height,max_width) \n",
        "        \n",
        "        if data_augmentation == True:\n",
        "            # Mode for flipping images used in data augmentation during training, \n",
        "            # choose one of [\"horizontal, \"vertical\", \"none\"].\n",
        "            _C.INPUT.RANDOM_FLIP = \"horizontal\" \n",
        "            # `True` if cropping is used for data augmentation during training.\n",
        "            _C.INPUT.CROP = CN({\"ENABLED\": True}) \n",
        "            # Cropping type. \n",
        "            # See documentation of `detectron2.data.transforms.RandomCrop` for explanation.\n",
        "            _C.INPUT.CROP.TYPE = \"relative_range\" \n",
        "            # Size of crop in range (0, 1] if CROP.TYPE is \"relative\" \n",
        "            # or \"relative_range\" and in number of pixels if CROP.TYPE is \"absolute\".\n",
        "            _C.INPUT.CROP.SIZE = [0.9, 0.9] \n",
        "\n",
        "    return _C"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J54HXpEQOMH9"
      },
      "source": [
        "def BB_FPN_PG_configs(cfg):\n",
        "\n",
        "    \"\"\"Parametrizes the configuration of the Backbone, FPN and Proposal \n",
        "    generator modules.\n",
        "\n",
        "    Args:\n",
        "        cfg (detectron2.config.config.CfgNode): Configuration node for \n",
        "        parameterization.\n",
        "\n",
        "    Returns: \n",
        "        _C (detectron2.config.config.CfgNode): Parameterized configuration node \n",
        "        of the of the Backbone, FPN and Proposal generator modules.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    _C = cfg  \n",
        "\n",
        "    # ------------------------------------------------------------------------ #\n",
        "    # Backbone options\n",
        "    # ------------------------------------------------------------------------ #\n",
        "    _C.MODEL.BACKBONE = CN()\n",
        "\n",
        "    _C.MODEL.BACKBONE.NAME = \"build_resnet_backbone\"\n",
        "    # Freeze the first several stages so they are not trained.\n",
        "    # There are 5 stages in ResNet. The first is a convolution, and the following\n",
        "    # stages are each group of residual blocks.\n",
        "    _C.MODEL.BACKBONE.FREEZE_AT = 2\n",
        "\n",
        "\n",
        "    # ------------------------------------------------------------------------ #\n",
        "    # FPN options\n",
        "    # ------------------------------------------------------------------------ #\n",
        "    _C.MODEL.FPN = CN()\n",
        "    # Names of the input feature maps to be used by FPN\n",
        "    # They must have contiguous power of 2 strides\n",
        "    # e.g., [\"res2\", \"res3\", \"res4\", \"res5\"]\n",
        "    _C.MODEL.FPN.IN_FEATURES = []\n",
        "    _C.MODEL.FPN.OUT_CHANNELS = 256\n",
        "\n",
        "    # Options: \"\" (no norm), \"GN\"\n",
        "    _C.MODEL.FPN.NORM = \"\"\n",
        "\n",
        "    # Types for fusing the FPN top-down and lateral features. \n",
        "    # Can be either \"sum\" or \"avg\"\n",
        "    _C.MODEL.FPN.FUSE_TYPE = \"sum\"\n",
        "\n",
        "\n",
        "    # ------------------------------------------------------------------------ #\n",
        "    # Proposal generator options\n",
        "    # ------------------------------------------------------------------------ #\n",
        "    _C.MODEL.PROPOSAL_GENERATOR = CN()\n",
        "    # Current proposal generators include \"RPN\", \"RRPN\" and \"PrecomputedProposals\"\n",
        "    _C.MODEL.PROPOSAL_GENERATOR.NAME = \"RPN\"\n",
        "    # Proposal height and width both need to be greater than MIN_SIZE\n",
        "    # (a the scale used during training or inference)\n",
        "    _C.MODEL.PROPOSAL_GENERATOR.MIN_SIZE = 0\n",
        "\n",
        "    return _C"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XTHQxgqQlAd"
      },
      "source": [
        "def Anchor_Generator_config(cfg):\n",
        "\n",
        "    \"\"\"Parametrizes the configuration of the anchor generator module.\n",
        "\n",
        "    Args:\n",
        "        cfg (detectron2.config.config.CfgNode): Configuration node for \n",
        "        parameterization.\n",
        "\n",
        "    Returns: \n",
        "        _C (detectron2.config.config.CfgNode): Parameterized configuration node \n",
        "        of the of the anchor generator module.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    _C = cfg\n",
        "    _C.MODEL.ANCHOR_GENERATOR = CN()\n",
        "    \n",
        "    # The generator can be any name in the ANCHOR_GENERATOR registry\n",
        "    _C.MODEL.ANCHOR_GENERATOR.NAME = \"DefaultAnchorGenerator\"\n",
        "\n",
        "    # Anchor sizes (i.e. sqrt of area) in absolute pixels w.r.t. the network input.\n",
        "    # Format: list[list[float]]. SIZES[i] specifies the list of sizes to use for\n",
        "    # IN_FEATURES[i]; len(SIZES) must be equal to len(IN_FEATURES) or 1.\n",
        "    # When len(SIZES) == 1, SIZES[0] is used for all IN_FEATURES.\n",
        "    _C.MODEL.ANCHOR_GENERATOR.SIZES = [[8, 16, 32, 48, 64, 96, 128, 196, 256, 320, 384, 512]]\n",
        "\n",
        "    # Anchor aspect ratios. For each area given in `SIZES`, anchors with different aspect\n",
        "    # ratios are generated by an anchor generator.\n",
        "    # Format: list[list[float]]. ASPECT_RATIOS[i] specifies the list of aspect ratios (H/W)\n",
        "    # to use for IN_FEATURES[i]; len(ASPECT_RATIOS) == len(IN_FEATURES) must be true,\n",
        "    # or len(ASPECT_RATIOS) == 1 is true and aspect ratio list ASPECT_RATIOS[0] is used\n",
        "    # for all IN_FEATURES.\n",
        "    _C.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.25, 0.5, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0]]\n",
        "\n",
        "    # Anchor angles.\n",
        "    # list[list[float]], the angle in degrees, for each input feature map.\n",
        "    # ANGLES[i] specifies the list of angles for IN_FEATURES[i].\n",
        "    _C.MODEL.ANCHOR_GENERATOR.ANGLES = [0, 90]\n",
        "\n",
        "    # Relative offset between the center of the first anchor and the top-left corner of the image\n",
        "    # Value has to be in [0, 1). Recommend to use 0.5, which means half stride.\n",
        "    # The value is not expected to affect model accuracy.\n",
        "    _C.MODEL.ANCHOR_GENERATOR.OFFSET = 0.5\n",
        "\n",
        "    return _C"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWJKQoMTyIXn"
      },
      "source": [
        "def RPN_config(cfg):\n",
        "\n",
        "    \"\"\"Parametrizes the configuration of the Region Proposal Network model.\n",
        "\n",
        "    Args:\n",
        "        cfg (detectron2.config.config.CfgNode): Configuration node for \n",
        "        parameterization.\n",
        "\n",
        "    Returns: \n",
        "        _C (detectron2.config.config.CfgNode): Parameterized configuration \n",
        "        node of the Region Proposal Network model.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    _C = cfg\n",
        "    _C.MODEL.RPN = CN()\n",
        "\n",
        "    _C.MODEL.RPN.HEAD_NAME = \"StandardRPNHead\"  # used by RPN_HEAD_REGISTRY\n",
        "    _C.MODEL.RPN.IOU_THRESHOLDS = [0.4, 0.7]\n",
        "    _C.MODEL.RPN.IOU_LABELS = [0, -1, 1]\n",
        "    # Number of regions per image used to train RPN\n",
        "    _C.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
        "    # Target fraction of foreground (positive) examples per RPN minibatch\n",
        "    _C.MODEL.RPN.POSITIVE_FRACTION = 0.5\n",
        "    # Options are: \"smooth_l1\", \"giou\"\n",
        "    _C.MODEL.RPN.BBOX_REG_LOSS_TYPE = \"smooth_l1\"\n",
        "    _C.MODEL.RPN.BBOX_REG_LOSS_WEIGHT = 1.0\n",
        "    # Weights on (dx, dy, dw, dh) for normalizing RPN anchor regression targets\n",
        "    _C.MODEL.RPN.BBOX_REG_WEIGHTS = (1.0, 1.0, 1.0, 1.0)\n",
        "    # The transition point from L1 to L2 loss. Set to 0.0 to make the loss simply L1.\n",
        "    _C.MODEL.RPN.SMOOTH_L1_BETA = 0.0\n",
        "    _C.MODEL.RPN.LOSS_WEIGHT = 1.0\n",
        "    # Number of top scoring RPN proposals to keep before applying NMS\n",
        "    # When FPN is used, this is *per FPN level* (not total)\n",
        "    _C.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 12000\n",
        "    _C.MODEL.RPN.PRE_NMS_TOPK_TEST = 6000\n",
        "    # Number of top scoring RPN proposals to keep after applying NMS\n",
        "    # When FPN is used, this limit is applied per level and then again to the union\n",
        "    # of proposals from all levels\n",
        "    # NOTE: When FPN is used, the meaning of this config is different from Detectron1.\n",
        "    # It means per-batch topk in Detectron1, but per-image topk here.\n",
        "    # See the \"find_top_rpn_proposals\" function for details.\n",
        "    _C.MODEL.RPN.POST_NMS_TOPK_TRAIN = 2000\n",
        "    _C.MODEL.RPN.POST_NMS_TOPK_TEST = 1000\n",
        "    # NMS threshold used on RPN proposals\n",
        "    _C.MODEL.RPN.NMS_THRESH = 0.6\n",
        "    # Set this to -1 to use the same number of output channels as input channels.\n",
        "    _C.MODEL.RPN.CONV_DIMS = [-1]\n",
        "    \n",
        "    return _C"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk5QOrQ-xzZl"
      },
      "source": [
        "def ROI_Heads_config(cfg):\n",
        "\n",
        "    \"\"\"Parametrizes the configuration of the ROI heads.\n",
        "\n",
        "    Args:\n",
        "        cfg (detectron2.config.config.CfgNode): Configuration node for \n",
        "        parameterization.\n",
        "\n",
        "    Returns: \n",
        "        _C (detectron2.config.config.CfgNode): Parameterized configuration \n",
        "        node of the ROI heads.\n",
        "\n",
        "    \"\"\"\n",
        "    _C = cfg\n",
        "    _C.MODEL.ROI_HEADS = CN()\n",
        "\n",
        "    _C.MODEL.ROI_HEADS.NAME = \"Res5ROIHeads\"\n",
        "    # Number of foreground classes\n",
        "    _C.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "    # Names of the input feature maps to be used by ROI heads\n",
        "    # Currently all heads (box, mask, ...) use the same input feature map list\n",
        "    # e.g., [\"p2\", \"p3\", \"p4\", \"p5\"] is commonly used for FPN\n",
        "    _C.MODEL.ROI_HEADS.IN_FEATURES = [\"res4\"]\n",
        "    # IOU overlap ratios [IOU_THRESHOLD]\n",
        "    # Overlap threshold for an RoI to be considered background (if < IOU_THRESHOLD)\n",
        "    # Overlap threshold for an RoI to be considered foreground (if >= IOU_THRESHOLD)\n",
        "    _C.MODEL.ROI_HEADS.IOU_THRESHOLDS = [0.5]\n",
        "    _C.MODEL.ROI_HEADS.IOU_LABELS = [0, 1]\n",
        "    # RoI minibatch size *per image* (number of regions of interest [ROIs])\n",
        "    # Total number of RoIs per training minibatch =\n",
        "    #   ROI_HEADS.BATCH_SIZE_PER_IMAGE * SOLVER.IMS_PER_BATCH\n",
        "    # E.g., a common configuration is: 512 * 16 = 8192\n",
        "    _C.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
        "    # Target fraction of RoI minibatch that is labeled foreground (i.e. class > 0)\n",
        "    _C.MODEL.ROI_HEADS.POSITIVE_FRACTION = 0.25\n",
        "\n",
        "    # Only used on test mode\n",
        "\n",
        "    # Minimum score threshold (assuming scores in a [0, 1] range); a value chosen to\n",
        "    # balance obtaining high recall with not having too many low precision\n",
        "    # detections that will slow down inference post processing steps (like NMS)\n",
        "    # A default threshold of 0.0 increases AP by ~0.2-0.3 but significantly slows down\n",
        "    # inference.\n",
        "    _C.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.05\n",
        "    # Overlap threshold used for non-maximum suppression (suppress boxes with\n",
        "    # IoU >= this threshold)\n",
        "    _C.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.5\n",
        "    # If True, augment proposals with ground-truth boxes before sampling proposals to\n",
        "    # train ROI heads.\n",
        "    _C.MODEL.ROI_HEADS.PROPOSAL_APPEND_GT = True\n",
        "\n",
        "    return _C"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN1LvMbSQtj5"
      },
      "source": [
        "def Box_Head_config(cfg):\n",
        "\n",
        "    \"\"\"Parametrizes the configuration of the ROI box heads.\n",
        "\n",
        "    Args:\n",
        "        cfg (detectron2.config.config.CfgNode): Configuration node \n",
        "        for parameterization.\n",
        "\n",
        "    Returns: \n",
        "        _C (detectron2.config.config.CfgNode): Parameterized configuration node \n",
        "        of the ROI box heads.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    _C = cfg\n",
        "    _C.MODEL.ROI_BOX_HEAD = CN()\n",
        "\n",
        "    # C4 don't use head name option\n",
        "    # Options for non-C4 models: FastRCNNConvFCHead,\n",
        "    _C.MODEL.ROI_BOX_HEAD.NAME = \"FastRCNNConvFCHead\"\n",
        "    # Options are: \"smooth_l1\", \"giou\"\n",
        "    _C.MODEL.ROI_BOX_HEAD.BBOX_REG_LOSS_TYPE = \"smooth_l1\"\n",
        "    # The final scaling coefficient on the box regression loss, used to balance the magnitude of its\n",
        "    # gradients with other losses in the model. See also `MODEL.ROI_KEYPOINT_HEAD.LOSS_WEIGHT`.\n",
        "    _C.MODEL.ROI_BOX_HEAD.BBOX_REG_LOSS_WEIGHT = 1.0\n",
        "    # Default weights on (dx, dy, dw, dh) for normalizing bbox regression targets\n",
        "    # These are empirically chosen to approximately lead to unit variance targets\n",
        "    _C.MODEL.ROI_BOX_HEAD.BBOX_REG_WEIGHTS = (10.0, 10.0, 5.0, 5.0)\n",
        "    # The transition point from L1 to L2 loss. Set to 0.0 to make the loss simply L1.\n",
        "    _C.MODEL.ROI_BOX_HEAD.SMOOTH_L1_BETA = 0.0\n",
        "    _C.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION = 14\n",
        "    _C.MODEL.ROI_BOX_HEAD.POOLER_SAMPLING_RATIO = 0\n",
        "    # Type of pooling operation applied to the incoming feature map for each RoI\n",
        "    _C.MODEL.ROI_BOX_HEAD.POOLER_TYPE = \"ROIAlignV2\"\n",
        "\n",
        "    _C.MODEL.ROI_BOX_HEAD.NUM_FC = 0\n",
        "    # Hidden layer dimension for FC layers in the RoI box head\n",
        "    _C.MODEL.ROI_BOX_HEAD.FC_DIM = 1024\n",
        "    _C.MODEL.ROI_BOX_HEAD.NUM_CONV = 0\n",
        "    # Channel dimension for Conv layers in the RoI box head\n",
        "    _C.MODEL.ROI_BOX_HEAD.CONV_DIM = 256\n",
        "    # Normalization method for the convolution layers.\n",
        "    # Options: \"\" (no norm), \"GN\", \"SyncBN\".\n",
        "    _C.MODEL.ROI_BOX_HEAD.NORM = \"\"\n",
        "    # Whether to use class agnostic for bbox regression\n",
        "    _C.MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG = False\n",
        "    # If true, RoI heads use bounding boxes predicted by the box head rather than proposal boxes.\n",
        "    _C.MODEL.ROI_BOX_HEAD.TRAIN_ON_PRED_BOXES = False\n",
        "\n",
        "    return _C"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlV6CMcM0mhh"
      },
      "source": [
        "def ResNets_config(cfg):\n",
        "\n",
        "    \"\"\"Parametrizes the configuration of the ResNet network/s.\n",
        "\n",
        "    Args:\n",
        "        cfg (detectron2.config.config.CfgNode): Configuration node for parameterization.\n",
        "\n",
        "    Returns: \n",
        "        _C (detectron2.config.config.CfgNode): Parameterized configuration node of the ResNet network/s.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    _C = cfg \n",
        "    _C.MODEL.RESNETS = CN()\n",
        "\n",
        "    # Note that parts of a resnet may be used for both the backbone and the head\n",
        "    # These options apply to both\n",
        "\n",
        "    _C.MODEL.RESNETS.DEPTH = 50\n",
        "    _C.MODEL.RESNETS.OUT_FEATURES = [\"res4\"]  # res4 for C4 backbone, res2..5 for FPN backbone\n",
        "\n",
        "    # Number of groups to use; 1 ==> ResNet; > 1 ==> ResNeXt\n",
        "    _C.MODEL.RESNETS.NUM_GROUPS = 1\n",
        "\n",
        "    # Options: FrozenBN, GN, \"SyncBN\", \"BN\"\n",
        "    _C.MODEL.RESNETS.NORM = \"FrozenBN\"\n",
        "\n",
        "    # Baseline width of each group.\n",
        "    # Scaling this parameters will scale the width of all bottleneck layers.\n",
        "    _C.MODEL.RESNETS.WIDTH_PER_GROUP = 64\n",
        "\n",
        "    # Place the stride 2 conv on the 1x1 filter\n",
        "    # Use True only for the original MSRA ResNet; use False for C2 and Torch models\n",
        "    _C.MODEL.RESNETS.STRIDE_IN_1X1 = True\n",
        "\n",
        "    # Apply dilation in stage \"res5\"\n",
        "    _C.MODEL.RESNETS.RES5_DILATION = 1\n",
        "\n",
        "    # Output width of res2. Scaling this parameters will scale the width of all 1x1 convs in ResNet\n",
        "    # For R18 and R34, this needs to be set to 64\n",
        "    _C.MODEL.RESNETS.RES2_OUT_CHANNELS = 256\n",
        "    _C.MODEL.RESNETS.STEM_OUT_CHANNELS = 64\n",
        "\n",
        "    # Apply Deformable Convolution in stages\n",
        "    # Specify if apply deform_conv on Res2, Res3, Res4, Res5\n",
        "    _C.MODEL.RESNETS.DEFORM_ON_PER_STAGE = [False, False, False, False]\n",
        "    # Use True to use modulated deform_conv (DeformableV2, https://arxiv.org/abs/1811.11168);\n",
        "    # Use False for DeformableV1.\n",
        "    _C.MODEL.RESNETS.DEFORM_MODULATED = False\n",
        "    # Number of groups in deformable conv.\n",
        "    _C.MODEL.RESNETS.DEFORM_NUM_GROUPS = 1\n",
        "\n",
        "    return _C"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wCIeD1iMSip"
      },
      "source": [
        "#Extract config properties\n",
        "cfg = get_cfg()\n",
        "Config = INPUT_config(cfg, train_dir=train_dir, test_dir=test_dir)\n",
        "Config = BB_FPN_PG_configs(Config)\n",
        "Config = Anchor_Generator_config(Config)\n",
        "Config = RPN_config(Config)\n",
        "Config = ROI_Heads_config(Config)\n",
        "Config = Box_Head_config(Config)\n",
        "Config = ResNets_config(Config)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BRsFSDHj9Fs"
      },
      "source": [
        "def save_config(cfg,file_name):\n",
        "\n",
        "    \"\"\"Saves the given configuration in the output and session's directories.\n",
        "\n",
        "    Args:\n",
        "        cfg (detectron2.config.config.CfgNode): Model's configuration.\n",
        "        file_name (str): Name for saving .yaml file (default is 'configuration.yaml').\n",
        "\n",
        "    \"\"\"\n",
        "    saving_path = \"/content/drive/MyDrive\" + '/' + file_name\n",
        "    \n",
        "    #Save configuration to file.\n",
        "    with open(saving_path, \"w\") as f:\n",
        "        f.write(cfg.dump())   \n",
        "    \n",
        "    #Copy output configuration in the session's directory.\n",
        "    !cp $saving_path $file_name\n",
        "    \n",
        "    #Check if the given configuration saved successfully.\n",
        "    test_cfg = get_cfg()\n",
        "    test_cfg.merge_from_file(file_name)\n",
        "    if test_cfg:\n",
        "        print(\"Model configuration saved successfully!\")\n",
        "        cfg.freeze()\n",
        "    else: print(\"Error in model configuration saving\")  "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jh23R9_oXPk"
      },
      "source": [
        "def inspect_yaml(configuration_dir):\n",
        "\n",
        "    \"\"\"Opens the input .yaml file and prints its key-value pairs.\n",
        "\n",
        "    Args:\n",
        "        configuration_dir (str): Saved configuration's directory.\n",
        "\n",
        "    \"\"\"\n",
        "    stream = open(configuration_dir, 'r')\n",
        "    dictionary = yaml.safe_load(stream)\n",
        "    for key, value in dictionary.items():\n",
        "        print('\\n')\n",
        "        print (key + \" : \" + str(value))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn9pwjHxkU_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f20472-70fe-482e-f026-ed2a02544392"
      },
      "source": [
        "save_config(Config, file_name = 'configuration_' + datetime_stamp() + '.yaml')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model configuration saved successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}